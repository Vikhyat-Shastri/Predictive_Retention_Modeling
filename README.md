
# ğŸ¯ Customer Churn Prediction System

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

> **An end-to-end production-ready machine learning system for predicting customer churn with advanced explainability and interactive deployment**

## ğŸŒŸ Project Highlights

This is a **comprehensive, production-ready** customer churn prediction system that goes beyond basic ML modeling. Built with industry best practices, it demonstrates:

- âœ… **Advanced ML Pipeline** - Production-grade sklearn Pipeline with automated preprocessing
- âœ… **Multiple ML Algorithms** - Random Forest, XGBoost, LightGBM with ensemble methods
- âœ… **Class Imbalance Handling** - SMOTEENN and ADASYN implementation
- âœ… **Model Explainability** - SHAP integration for transparent AI decisions
- âœ… **Customer Segmentation** - K-Means clustering with business insights
- âœ… **Interactive Web App** - Streamlit dashboard for real-time predictions
- âœ… **REST API** - FastAPI backend for production integration
- âœ… **Docker Deployment** - Containerized application ready for cloud deployment
- âœ… **Comprehensive Testing** - Unit tests and API tests with pytest
- âœ… **CI/CD Pipeline** - GitHub Actions for automated testing and deployment

## ğŸ“Š Business Impact

- **Predict** customer churn with **74%+ accuracy** (77% recall)
- **Explain** predictions using SHAP values for actionable insights
- **Segment** customers into distinct groups for targeted retention strategies
- **Deploy** easily with Docker containers or cloud platforms
- **Scale** with production-ready API and monitoring

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Data Layer                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  Raw Data  â”‚â†’ â”‚ Preprocessingâ”‚â†’ â”‚Feature Eng.  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ML Pipeline Layer                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   SMOTE    â”‚â†’ â”‚ ML Ensemble  â”‚â†’ â”‚ SHAP Explainer â”‚      â”‚
â”‚  â”‚  ADASYN    â”‚  â”‚ RF/XGB/LGBM  â”‚  â”‚   K-Means      â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Application Layer                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  FastAPI REST   â”‚              â”‚   Streamlit      â”‚      â”‚
â”‚  â”‚     API         â”‚              â”‚    Web App       â”‚      â”‚
â”‚  â”‚  (Port 8000)    â”‚              â”‚  (Port 8501)     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
Predictive_Retention_Modeling/
â”œâ”€â”€ ğŸ“Š data/
â”‚   â””â”€â”€ Telco_customer_churn.csv        # Dataset
â”‚
â”œâ”€â”€ ğŸ“ models/                          # Trained models & artifacts
â”‚   â”œâ”€â”€ churn_model_pipeline.pkl        # Main prediction model
â”‚   â”œâ”€â”€ segmentation_model.pkl          # Customer segmentation
â”‚   â”œâ”€â”€ shap_explainer.pkl              # SHAP explainer
â”‚   â”œâ”€â”€ segments_visualization.png      # Segment analysis
â”‚   â”œâ”€â”€ shap_summary.png                # SHAP summary plots
â”‚   â””â”€â”€ explanations/                   # Individual explanations
â”‚
â”œâ”€â”€ ğŸ““ notebooks/
â”‚   â””â”€â”€ churn_analysis.ipynb            # Exploratory analysis
â”‚
â”œâ”€â”€ ğŸ§  src/                             # Core ML modules
â”‚   â”œâ”€â”€ pipeline.py                     # Advanced ML pipeline
â”‚   â”œâ”€â”€ segmentation.py                 # Customer segmentation
â”‚   â”œâ”€â”€ explainability.py               # SHAP integration
â”‚   â”œâ”€â”€ preprocess.py                   # Data preprocessing
â”‚   â”œâ”€â”€ train.py                        # Model training
â”‚   â”œâ”€â”€ eda.py                          # Data analysis
â”‚   â”œâ”€â”€ inference.py                    # Predictions
â”‚   â””â”€â”€ utils.py                        # Utilities
â”‚
â”œâ”€â”€ ğŸŒ app/                             # Web applications
â”‚   â”œâ”€â”€ streamlit_app.py                # Interactive dashboard
â”‚   â””â”€â”€ api.py                          # FastAPI REST API
â”‚
â”œâ”€â”€ ğŸ§ª tests/                           # Test suite
â”‚   â”œâ”€â”€ test_pipeline.py                # Pipeline tests
â”‚   â””â”€â”€ test_api.py                     # API tests
â”‚
â”œâ”€â”€ ğŸ³ Docker files
â”‚   â”œâ”€â”€ Dockerfile.api                  # API container
â”‚   â”œâ”€â”€ Dockerfile.streamlit            # Streamlit container
â”‚   â””â”€â”€ docker-compose.yml              # Orchestration
â”‚
â”œâ”€â”€ âš™ï¸ .github/workflows/
â”‚   â””â”€â”€ ci-cd.yml                       # CI/CD pipeline
â”‚
â”œâ”€â”€ ğŸ“œ Configuration files
â”‚   â”œâ”€â”€ requirements.txt                # Python dependencies
â”‚   â”œâ”€â”€ setup.py                        # Package setup
â”‚   â””â”€â”€ train_models.py                 # Training script
â”‚
â””â”€â”€ ğŸ“– README.md                        # This file
```

## ğŸš€ Quick Start

### 1ï¸âƒ£ Installation

```bash
# Clone the repository
git clone https://github.com/Vikhyat-Shastri/Predictive_Retention_Modeling.git
cd Predictive_Retention_Modeling

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2ï¸âƒ£ Train Models

```bash
# Train all models (Pipeline, Segmentation, SHAP)
python train_models.py
```

This will:
- âœ… Load and preprocess data
- âœ… Train multiple ML models (RF, XGBoost, LightGBM, Ensembles)
- âœ… Perform customer segmentation
- âœ… Generate SHAP explanations
- âœ… Save all models and artifacts

### 3ï¸âƒ£ Run Applications

#### Option A: Streamlit Web App

```bash
streamlit run app/streamlit_app.py
```

Visit: `http://localhost:8501`

#### Option B: FastAPI REST API

```bash
cd app
python api.py
```

Visit API docs: `http://localhost:8000/docs`

#### Option C: Docker (Recommended for Production)

```bash
# Build and start all services
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

Services:
- ğŸŒ Streamlit: `http://localhost:8501`
- ğŸ”Œ API: `http://localhost:8000`
- ğŸ“š API Docs: `http://localhost:8000/docs`

## ğŸ¯ Features

### 1. ğŸ”® Real-Time Churn Prediction

- **Input customer data** through web form or API
- **Get instant predictions** with probability scores
- **Risk assessment** (Low/Medium/High)
- **Actionable recommendations** based on risk level

### 2. ğŸ” Model Explainability (SHAP)

- **Feature importance** - See which factors matter most
- **Individual explanations** - Understand each prediction
- **Force plots** - Visualize feature contributions
- **Waterfall plots** - Step-by-step prediction breakdown

### 3. ğŸ‘¥ Customer Segmentation

- **K-Means clustering** identifies 4 distinct customer groups
- **Segment profiles** with demographics and behavior
- **Churn analysis** by segment
- **Targeted strategies** for each segment

### 4. ğŸ“Š Interactive Dashboard

Multi-page Streamlit application:
- ğŸ  **Home** - Overview and introduction
- ğŸ”® **Prediction** - Make churn predictions
- ğŸ” **Explanation** - SHAP-based insights
- ğŸ‘¥ **Segmentation** - Customer group analysis
- ğŸ“ˆ **Performance** - Model metrics

### 5. ğŸ”Œ Production REST API

FastAPI endpoints:
- `GET /health` - Health check
- `GET /model/info` - Model information
- `POST /predict` - Single prediction
- `POST /predict/batch` - Batch predictions
- `POST /predict/file` - Upload CSV for predictions
- `POST /explain` - Get SHAP explanation
- `GET /segments/info` - Segment information

## ğŸ“Š Model Performance

| Model | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|-------|----------|-----------|--------|----------|---------|
| **LightGBM (Current)** | 74.0% | 50.7% | 77.3% | 61.2% | 82.2% |

**Note:** Current model is optimized for high recall (77.3%) to catch more potential churners, accepting lower precision. This is ideal for retention campaigns where missing a churner is more costly than false alarms.

## ğŸ› ï¸ Technology Stack

### Machine Learning
- **Scikit-learn** - ML pipeline and preprocessing
- **LightGBM** - Gradient boosting
- **XGBoost** - Gradient boosting
- **Imbalanced-learn** - SMOTE, ADASYN

### Explainability & Analysis
- **SHAP** - Model explanations
- **K-Means** - Customer segmentation
- **Pandas** - Data manipulation
- **NumPy** - Numerical computing

### Visualization
- **Plotly** - Interactive plots
- **Matplotlib** - Static visualizations
- **Seaborn** - Statistical plots

### Web & API
- **Streamlit** - Interactive dashboard
- **FastAPI** - REST API
- **Uvicorn** - ASGI server
- **Pydantic** - Data validation

### DevOps & Testing
- **Docker** - Containerization
- **Pytest** - Testing framework
- **GitHub Actions** - CI/CD
- **Black** - Code formatting

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html

# Run specific test file
pytest tests/test_pipeline.py -v

# Run API tests
pytest tests/test_api.py -v
```

## ğŸ“ˆ Usage Examples

### Python API

```python
from src.pipeline import ChurnPredictionPipeline
from src.explainability import ModelExplainer
import pandas as pd

# Load model
pipeline = ChurnPredictionPipeline.load_model('models/churn_model_pipeline.pkl')

# Make prediction
customer_data = pd.DataFrame({...})  # Your customer data
prediction = pipeline.predict(customer_data)
probability = pipeline.predict_proba(customer_data)

# Get explanation
explainer = ModelExplainer(pipeline.pipeline)
explanation = explainer.explain_instance(customer_data, index=0)
```

### REST API

```python
import requests

# Make prediction
response = requests.post('http://localhost:8000/predict', json={
    "gender": "Female",
    "SeniorCitizen": 0,
    "tenure": 12,
    # ... other fields
})

result = response.json()
print(f"Prediction: {result['prediction_label']}")
print(f"Churn Risk: {result['churn_probability']:.2%}")
```

## ğŸ“ Key Learnings & Innovations

1. **Production-Ready Pipeline** - Full sklearn Pipeline with custom transformers
2. **Advanced Imbalance Handling** - Compared SMOTEENN vs ADASYN
3. **Ensemble Methods** - Voting and stacking classifiers
4. **SHAP Integration** - Transparent AI with feature explanations
5. **Customer Segmentation** - K-Means with business insights
6. **API Design** - RESTful API with proper validation
7. **Containerization** - Docker multi-service deployment
8. **Testing** - Comprehensive unit and integration tests
9. **CI/CD** - Automated testing and deployment pipeline

## ğŸ‘¥ Team & Contributions

This project demonstrates proficiency in:
- **Machine Learning Engineering** - Pipeline design, model training
- **Data Science** - EDA, segmentation, feature engineering
- **MLOps** - Deployment, monitoring, CI/CD
- **Software Engineering** - API design, testing, documentation
- **DevOps** - Docker, containerization, orchestration

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file for details

## ğŸ™ Acknowledgments

- Dataset: [Telco Customer Churn](https://www.kaggle.com/blastchar/telco-customer-churn)
- SHAP Library: [shap.readthedocs.io](https://shap.readthedocs.io)

## ğŸ“§ Contact

**Vikhyat Shastri**
- GitHub: [@Vikhyat-Shastri](https://github.com/Vikhyat-Shastri)
- Project: [Predictive_Retention_Modeling](https://github.com/Vikhyat-Shastri/Predictive_Retention_Modeling)

---

â­ **Star this repository if you find it helpful!** â­